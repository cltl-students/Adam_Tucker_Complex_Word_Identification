{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "848f2ada-e8ea-48d6-ab7a-92dbcff7044a",
   "metadata": {},
   "source": [
    "This notebook takes the features from the CAMB inspired system and evaluates for the probabilitic complexity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1b794f1-bf88-4d9e-bde9-8650e36424f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e792d80-0f1d-4175-b0e5-5db11f60a445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Models/prob/News_prob_CAMB.pkl\tMAE: 0.10285842685760904\n",
      "Model: Models/prob/Wikinews_prob_CAMB.pkl\tMAE: 0.1026810989773711\n",
      "Model: Models/prob/Wikipedia_prob_CAMB.pkl\tMAE: 0.10305216575989859\n",
      "Model: Models/prob/Combined_prob_CAMB.pkl\tMAE: 0.10148337967620562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamtucker/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:299: UserWarning: Trying to unpickle estimator LinearRegression from version 1.2.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/adamtucker/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:299: UserWarning: Trying to unpickle estimator LinearRegression from version 1.2.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/adamtucker/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:299: UserWarning: Trying to unpickle estimator LinearRegression from version 1.2.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/adamtucker/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:299: UserWarning: Trying to unpickle estimator LinearRegression from version 1.2.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def run_models(classifiers, testing_features):  # testing_features is now a DataFrame\n",
    "    \n",
    "\n",
    "    # Extract the feature columns from the testing features DataFrame\n",
    "    feature_columns = ['syllables', 'length', 'dep num', 'synonyms', 'hypernyms', 'ogden', 'simple_wiki', 'CNC', 'IMG', 'sub_imdb', 'google frequency', 'KFCAT', 'FAM', 'KFSMP', 'KFFRQ', 'AOA', 'NPHN', 'T-LFRQ' ]\n",
    "    X_test = testing_features[feature_columns].values\n",
    "\n",
    "    # Replace NaN values with 0\n",
    "    imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "    X_test = imputer.fit_transform(X_test)\n",
    "\n",
    "    # Create an empty DataFrame to store the predictions\n",
    "    predictions_df = pd.DataFrame()\n",
    "\n",
    "    for classifier_file in classifiers:\n",
    "        # Load the trained model from the pickle file\n",
    "        with open(classifier_file, 'rb') as file:\n",
    "            classifier = pickle.load(file)\n",
    "\n",
    "        # Make predictions using the model\n",
    "        y_pred = classifier.predict(X_test)\n",
    "\n",
    "        # Add the predictions to the DataFrame\n",
    "        predictions_df[classifier_file] = y_pred\n",
    "\n",
    "    # Add the 'complex_probabilistic' label from the testing features file to the DataFrame\n",
    "    predictions_df['complex_probabilistic'] = testing_features['complex_probabilistic'].values\n",
    "\n",
    "    return predictions_df\n",
    "\n",
    "def evaluate(predictions_df):\n",
    "    # Get the predicted values and actual labels\n",
    "    y_pred = predictions_df['complex_probabilistic']\n",
    "    y_true = testing_features ['complex_probabilistic'] \n",
    "\n",
    "    # Calculate MAE for each model\n",
    "    mae_per_model = {}\n",
    "    for column in predictions_df.columns[:-1]:\n",
    "        mae = mean_absolute_error(y_true, predictions_df[column])\n",
    "        mae_per_model[column] = mae\n",
    "\n",
    "    return mae_per_model\n",
    "\n",
    "# Define the trained classifier files\n",
    "classifiers = [\n",
    "    \"Models/prob/News_prob_CAMB.pkl\",\n",
    "    \"Models/prob/Wikinews_prob_CAMB.pkl\",\n",
    "    \"Models/prob/Wikipedia_prob_CAMB.pkl\",\n",
    "    \"Models/prob/Combined_prob_CAMB.pkl\"\n",
    "]\n",
    "\n",
    "\n",
    "# Define the testing features file paths\n",
    "\n",
    "testing_features_files = [\n",
    "    \"All_features/Wikipedia_Dev_pp.pkl\"]\n",
    "    \n",
    "\n",
    "\n",
    "# Load each testing features file into a separate DataFrame\n",
    "testing_feature_dfs = [pd.read_pickle(file) for file in testing_features_files]\n",
    "\n",
    "# Concatenate the separate DataFrames into a single DataFrame\n",
    "testing_features = pd.concat(testing_feature_dfs)\n",
    "\n",
    "# Run the models and make predictions\n",
    "predictions_df = run_models(classifiers, testing_features)\n",
    "\n",
    "\n",
    "# Evaluate the predictions using MAE for each model\n",
    "mae_per_model = evaluate(predictions_df)\n",
    "\n",
    "# Print the MAE for each model\n",
    "for model, mae in mae_per_model.items():\n",
    "    print(f\"Model: {model}\\tMAE: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ff1d15-b9cb-42de-8fee-5b5d22d4824b",
   "metadata": {},
   "source": [
    "Model: lmodel/prob/News_prob.pkl\tMAE: 0.11361416574728281\n",
    "Model: lmodel/prob/Wikinews_prob.pkl\tMAE: 0.11148948763200345\n",
    "Model: lmodel/prob/Wikipedia_prob.pkl\tMAE: 0.11352341079626468\n",
    "Model: lmodel/prob/Combined_prob.pkl\tMAE: 0.11281649160711754"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ada1b35f-e4bd-44eb-a737-32f35bb78878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{MAE per Model - final_camb_feats_Test/combined_Test_Final.pkl}\n",
      "\\label{table:final_camb_feats_Test/combined_Test_Final.pkl}\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "    Model &    MAE \\\\\n",
      "\\midrule\n",
      "     NEWS & 0.1079 \\\\\n",
      " WIKINEWS & 0.1062 \\\\\n",
      "WIKIPEDIA & 0.1070 \\\\\n",
      " Combined & 0.1061 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qm/g52sxk4d4qsg16xphqz6vvtc0000gn/T/ipykernel_47551/3185660037.py:25: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = mae_df.to_latex(index=False, caption=f\"MAE per Model - {testing_feature_file}\", label=f\"table:{testing_feature_file}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NEWS': 0.10786376245846555,\n",
       " 'WIKINEWS': 0.1061570633409926,\n",
       " 'WIKIPEDIA': 0.10698594475258484,\n",
       " 'Combined': 0.1060734513675542}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def evaluate(predictions_df, testing_feature_file):\n",
    "    # Get the predicted values and actual labels\n",
    "    y_pred = predictions_df['complex_probabilistic']\n",
    "    y_true = testing_features['complex_probabilistic'] \n",
    "\n",
    "    # Define the model names\n",
    "    model_names = [\"NEWS\", \"WIKINEWS\", \"WIKIPEDIA\", \"Combined\"]\n",
    "\n",
    "    # Calculate MAE for each model\n",
    "    mae_per_model = {}\n",
    "    for i, column in enumerate(predictions_df.columns[:-1]):\n",
    "        mae = mean_absolute_error(y_true, predictions_df[column])\n",
    "        mae_per_model[model_names[i]] = mae\n",
    "\n",
    "    # Create a DataFrame to store the MAE per model\n",
    "    mae_df = pd.DataFrame(list(mae_per_model.items()), columns=['Model', 'MAE'])\n",
    "\n",
    "    # Format MAE values to 4 decimal places\n",
    "    mae_df['MAE'] = mae_df['MAE'].apply(lambda x: \"{:.4f}\".format(x))\n",
    "\n",
    "    # Print the MAE DataFrame in LaTeX format\n",
    "    latex_table = mae_df.to_latex(index=False, caption=f\"MAE per Model - {testing_feature_file}\", label=f\"table:{testing_feature_file}\")\n",
    "    print(latex_table)\n",
    "\n",
    "    return mae_per_model\n",
    "\n",
    "# Replace 'predictions_df' and 'testing_features' with your actual data\n",
    "# evaluate(predictions_df, testing_features_file)\n",
    "\n",
    "evaluate(predictions_df, testing_features_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5125cb0-f890-4b5e-8b0e-8da1683ef15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lmodel/prob/News_prob_CAMB.pkl': 0.10786376245846555, 'lmodel/prob/Wikinews_prob_CAMB.pkl': 0.1061570633409926, 'lmodel/prob/Wikipedia_prob_CAMB.pkl': 0.10698594475258484, 'lmodel/prob/Combined_prob_CAMB.pkl': 0.1060734513675542}\n"
     ]
    }
   ],
   "source": [
    "print(mae_per_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc39c558-c8d4-4b3b-8e3c-44a3f8499752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
